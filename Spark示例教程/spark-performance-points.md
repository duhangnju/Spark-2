# Spark关键性能考量
主要来源《Spark快速数据分析》

- 并行度

## 1. 并行度
RDD 的逻辑表示其实是一个对象集合。在物理执行期间, RDD 会被分为一系列的分区,每个分区都是整个数据的子集。当 Spark 调度并运行任务时,Spark 会为每个分区中的数据创建出一个任务。该任务在默认情况下会需要集群中的一个计算核心来执行。Spark 也会针对 RDD 直接自动推断出合适的并行度,这对于大多数用例来说已经足够了。输入 RDD 一般会根据其底层的存储系统选择并行度。例如,从 HDFS 上读数据的输入 RDD 会为数据在 HDFS 上的每个文件区块创建一个分区。从数据混洗后的 RDD 派生下来的 RDD 则会采用与其父 RDD 相同的并行度。

### 并行度会从两方面影响程序的性能:

- 当并行度过低时: Spark 集群会出现资源闲置的情况。比如, 假设你的应用有 1000 个可使用的计算核心, 但所运行的步骤只有 30 个任务, 你就应该提高并行度来充分利用更多的计算核心。
- 当并行度过高时: 每个分区产生的间接开销累计起来就会更大。评判并行度是否过高的标准包括任务是否是几乎在瞬间(毫秒级)完成的, 或者是否观察到任务没有读写任何数据。

### Spark提供了两种方法来对操作的并行度进行调优

- 第一种方法是在数据混洗操作时, 使用参数的方式为混洗后的 RDD 指定并行度。
- 第二种方法是对于任何已有的 RDD, 可以进行重新分区来获取更多或者更少的分区数。重新分区操作通过 repartition() 实现, 该操作会把 RDD 随机打乱并分成设定的分区数目。如果你确定要减少 RDD 分区, 可以使用 coalesce() 操作。由于没有打乱数据,该操作比 repartition() 更为高效。

如果你认为当前的并行度过高或者过低,可以利用这些方法对数据分布进行重新调整。 

举个例子,假设我们从 S3 上读取了大量数据,然后马上进行 filter() 操作筛选掉数据集中的绝大部分数据。默认情况下, filter() 返回的 RDD 的分区数和其父节点一样,这样可能会产生很多空的分区或者只有很少数据的分区。在这样的情况下,可以通过合并得到分区更少的 RDD 来提高应用性能.

## 2. 内存管理

### 内存用途

- RDD存储: 当调用 RDD 的 persist() 或 cache() 方法时,这个 RDD 的分区会被存储到缓存区中。 Spark 会根据 spark.storage.memoryFraction 限制用来缓存的内存占整个 JVM 堆空间的比例大小。如果超出限制,旧的分区数据会被移出内存。
- 数据混洗与聚合的缓存区: 当进行数据混洗操作时,Spark 会创建出一些中间缓存区来存储数据混洗的输出数据。这些缓存区用来存储聚合操作的中间结果,以及数据混洗操作中直接输出的部分缓存数据。 Spark 会尝试根据 spark.shuffle.memoryFraction 限定这种缓存区内存占总内存的比例。
- 用户代码: Spark可以执行任意的用户代码,所以用户的函数可以自行申请大量内存。例如,如果一个用户应用分配了巨大的数组或者其他对象,那这些都会占用总的内存。用户代码可以访问 JVM 堆空间中除分配给 RDD 存储和数据混洗存储以外的全部剩余空间。

在默认情况下,Spark 会使用 60%的空间来存储 RDD,20% 存储数据混洗操作产生的数据,剩下的 20% 留给用户程序。用户可以自行调节这些选项来追求更好的性能表现。如果用户代码中分配了大量的对象,那么降低 RDD 存储和数据混洗存储所占用的空间可以有效避免程序内存不足的情况。

除了调整内存各区域比例,我们还可以为一些工作负载改进缓存行为的某些要素。Spark
默认的 cache() 操作会以 MEMORY_ONLY 的存储等级持久化数据。这意味着如果缓存新的




